# LangChain Prompts

## ğŸ“Œ Definition

A **prompt** is an instruction or query given to a language model (LLM) that guides its response.  
Prompts enable natural language interaction with AI, reducing the need for direct coding.

---

## ğŸ§© Prompt Templates

**Purpose:** Structure prompts to make them reusable and adaptable.  
ğŸ‘‰ Instead of hardcoding, templates use **placeholders** for dynamic values and context.

### ğŸ”¹ Types

1. **Text Prompt Templates**

   - Input: A string of text
   - Output: A formatted prompt

2. **Chat Prompt Templates**
   - Input: List of messages (role-based: _System, Human, AI_)
   - Each message can include variables

### ğŸ”¹ Variables

- Use placeholders like `{input}` or `{context}`
- Replaced with user-provided or system-generated data at runtime

---

## ğŸ¯ Prompt Engineering

- **Zero-shot Prompts:** Rely only on the task/question and LLMâ€™s training.
- **Few-shot Prompts:** Include a few examples in the prompt for more accurate/specific responses.
- **Dynamic & Reusable Prompts:**
  - Example: Summarization prompts with adjustable tone or topic.
  - Reuse across apps for consistency.

---

## ğŸ› ï¸ Managing Prompts in LangChain

- **Structure:** Keep prompt logic separate from application code.
- **Versioning:** Different prompt versions for dev/test/production.
- **Composability:** Combine prompts so one output becomes anotherâ€™s input (pipeline workflows).

---

## ğŸ’» Example Code

```python
from langchain.prompts import PromptTemplate

# Define a simple template
template = PromptTemplate(
    input_variables=["name", "task"],
    template="Hello {name}, could you please help me with {task}?"
)

prompt = template.format(name="Alice", task="data analysis")
print(prompt)
# Output: Hello Alice, could you please help me with data analysis?
```
